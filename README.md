# Nanashi
Config files for my GitHub profile.
# Nanashi üöÄüîíüêù

**IA souveraine on-device ‚Äì Privacy absolue, sans nom, sans trace**

Nanashi (ÁÑ°Âêç ‚Äì "sans nom" en japonais) est une intelligence artificielle locale, 100 % on-device, optimis√©e exclusivement pour Apple Silicon (M-series : Mac Mini Pro, MacBook, iPhone, iPad).

Aucune donn√©e ne quitte jamais votre appareil. Z√©ro cloud, z√©ro fuite.

### Fonctionnalit√©s principales
- **Privacy absolue** : Split inference avec injection de bruit additif ‚Äì vos donn√©es restent sur l'appareil, jamais expos√©es.
- **Nanashi Consensus** : Proof of Intelligence anonyme (pr√©paration future subnet Bittensor privacy).
- **Performance native** : Inf√©rence ultra-rapide via Ollama + MLX (framework Apple) ‚Äì Llama 3.1, Mistral et mod√®les ouverts √† pleine vitesse Neural Engine.
- **UI premium** : Interface neon/glassmorphism responsive (dashboard mining simul√©, chat s√©curis√©, audit s√©curit√©, settings).
- **Mode hybride** : Local souverain + contribution anonyme d√©centralis√©e (Bittensor / io.net en roadmap).

### Pourquoi Nanashi ?
- Privacy > tout (contrairement aux concurrents semi-ouverts ou cloud-d√©pendants).
- Exclusif Apple Silicon (march√© massif inexploit√© en IA d√©centralis√©e).
- Open-source MIT ‚Äì libre √† utiliser, modifier, d√©ployer.

### D√©mo instantan√©e (Mac M-series)
```bash
# 1. Installer Ollama
brew install ollama

# 2. Lancer Ollama en arri√®re-plan
ollama serve &

# 3. T√©l√©charger un mod√®le
ollama pull llama3.1:8b

# 4. Ouvrir l'interface
open index.html